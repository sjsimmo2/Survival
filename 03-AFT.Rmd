# Accelerated Failure Time models

The following R codes illustrate how to fit the Accelerated Failure Time models.

```{r packages,include=F}
library(survival)
library(foreign)
library(ggplot2)
library(survminer)
library(rms)
library(flexsurv)
library(dplyr)
library(ciTools)
library(here)
library(visreg)
library(cmprsk)

library(reticulate)

use_python("C:\\ProgramData\\Anaconda3\\python.exe")

```




```{r, include=FALSE}
loyalty=read.csv("Q:/My Drive/Fall 3 - Survival Analysis/loyalty.csv",header=T)
recid=read.csv("Q:/My Drive/Fall 3 - Survival Analysis/recid.csv",header=T)
recid_long=read.csv("Q:/My Drive/Fall 3 - Survival Analysis/recid_long.csv",header=T)
recid_lag=read.csv("Q:/My Drive/Fall 3 - Survival Analysis/recid_lag.csv",header=T)
leaders = read.csv(file = "Q:/My Drive/Fall 3 - Survival Analysis/leaders.csv", header = TRUE)
bladder = read.csv(file = "Q:/My Drive/Fall 3 - Survival Analysis/bladder.csv", header = TRUE)

```



```{r AFT}

# Accelerated Failure Time Model 
recid.aft.ln <- survreg(Surv(week, arrest) ~ fin + age + mar + prio, data = recid, dist = 'lognormal')
summary(recid.aft.ln)
#Parameter interpretation
(exp(coef(recid.aft.ln))-1)*100

# Exponential vs. Weibull 
recid.aft.w <- survreg(Surv(week, arrest) ~ fin + age  + wexp + mar + paro + prio, data = recid, dist = 'weibull')
summary(recid.aft.w)

# Checking Distributions 
recid.aft.w <- flexsurvreg(Surv(week, arrest) ~ fin + age + wexp + mar + paro + prio, data = recid, dist = "weibull")

plot(recid.aft.w, type = "cumhaz", ci = TRUE, conf.int = FALSE, las = 1, bty = "n",
     xlab = "week", ylab = "Cumulative Hazard", main = "Weibull Distribution")

recid.aft.e <- flexsurvreg(Surv(week, arrest) ~ fin + age + wexp + mar + paro + prio, data = recid, dist = "exp")

plot(recid.aft.e, type = "cumhaz", ci = TRUE, conf.int = FALSE, las = 1, bty = "n",
     xlab = "week", ylab = "Cumulative Hazard", main = "Exponential Distribution")

recid.aft.g <- flexsurvreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = "gengamma")

plot(recid.aft.g, type = "cumhaz", ci = TRUE, conf.int = FALSE, las = 1, bty = "n",
     xlab = "week", ylab = "Cumulative Hazard", main = "Gamma Distribution")

recid.aft.ll <- flexsurvreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = "llogis")

plot(recid.aft.ll, type = "cumhaz", ci = TRUE, conf.int = FALSE, las = 1, bty = "n",
     xlab = "week", ylab = "Cumulative Hazard", main = "Log-Logistic Distribution")

recid.aft.ln <- flexsurvreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = "lognormal")

plot(recid.aft.ln, type = "cumhaz", ci = TRUE, conf.int = FALSE, las = 1, bty = "n",
     xlab = "week", ylab = "Cumulative Hazard", main = "Log-Normal Distribution")


# Goodness-of-Fit Tests 

like.e = flexsurvreg(Surv(week, arrest) ~ fin + age +  wexp + mar + paro + prio, data = recid, dist = "exp")$loglik
like.w <- flexsurvreg(Surv(week, arrest) ~ fin + age +  wexp + mar + paro + prio, data = recid, dist = "weibull")$loglik
like.ln <- flexsurvreg(Surv(week, arrest) ~ fin + age +  wexp + mar + paro + prio, data = recid, dist = "lnorm")$loglik
like.g = flexsurvreg(Surv(week, arrest) ~ fin + age  + wexp + mar + paro + prio, data = recid, dist = "gengamma")$loglik
like.ll = flexsurvreg(Surv(week, arrest) ~ fin + age  + wexp + mar + paro + prio, data = recid, dist = "llogis")$loglik
like.f = flexsurvreg(Surv(week, arrest) ~ fin + age  + wexp + mar + paro + prio, data = recid, dist = "genf")$loglik

pval.e.g = pchisq((-2*(like.e-like.g)), 2,lower.tail=F)
pval.w.g = pchisq((-2*(like.w-like.g)), 1,lower.tail=F)
pval.ln.g = pchisq((-2*(like.ln-like.g)), 1,lower.tail=F)
##pval.g.f = pchisq((-2*(like.g-like.f)), 1,lower.tail=F)


Tests = c('Exp vs. Gam', 'Wei vs. Gam', 'LogN vs. Gam')
P_values = c(pval.e.g, pval.w.g, pval.ln.g)
cbind(Tests, P_values)

# Predicted Survival Quantiles 
recid.aft.w = survreg(Surv(week, arrest) ~ fin + age +prio, data = recid, dist = 'weibull')
summary(recid.aft.w)

survprob.75.50.25 = predict(recid.aft.w, type = "quantile", se.fit = TRUE,p = c(0.25, 0.5, 0.75))
head(survprob.75.50.25$fit)


# Predicted Mean Event Time #
p.time.mean = predict(recid.aft.w, type = "response", se.fit = TRUE)
head(p.time.mean$fit, n = 10)

# Predicted Survival Probabilities #
survprob.actual = 1 - psurvreg(recid$week,
      mean = predict(recid.aft.w, type = "lp"),
      scale = recid.aft.w$scale, distribution =     recid.aft.w$dist)
head(survprob.actual, n = 10)

survprob.10wk = 1 - psurvreg(10,
    mean = predict(recid.aft.w, type = "lp"),
    scale = recid.aft.w$scale,
    distribution = recid.aft.w$dist)
head(survprob.10wk)

# Predicted Change in Event Time #
new_time = qsurvreg(1 - survprob.actual,
  mean = predict(recid.aft.w, type = "lp") +
  coef(recid.aft.w)['fin'],
  scale = recid.aft.w$scale,
  distribution = recid.aft.w$dist)

recid$new_time = new_time
recid$diff = recid$new_time - recid$week

head(data.frame(recid$week, recid$new_time, recid$diff), n = 10)


```

Let's break down this code into smaller chunks to understand what is going on in each one...

## Predict mean survival
In the survival regression, when we use the predict command (with nothing else), this is predicting the mean survival time.  This means, on average when do we think the event will occur?  For example, we will continue to use the recidivism data set with the Weibull distribution with the variables fin, age and prior.  The following command will predict the mean time of the event occurring (only printing off a few to see).


```{r AFT predict mean}

recid.aft.w = survreg(Surv(week, arrest) ~ fin + age +prio, data = recid, dist = 'weibull')
head(predict(recid.aft.w))

```

## Predict quantiles
But does it make sense to predict on average when we think an event will occur (or when an event will fail)? Probably not.  Another approach would be to print the quantiles (for example the 25th, 50th and 75th quantile).

```{r AFT quantiles}

survprob.75.50.25 = predict(recid.aft.w, type = "quantile", se.fit = TRUE,p = c(0.25, 0.5, 0.75))
head(survprob.75.50.25$fit)
```

## Percentiles for an individual person
Did you know that from this regression, each observation has their own survival curve?  That is why we can get quantiles (we can go the "opposite" direction and get percentiles too!).  Below you will find the survival curve for person 1...

```{r Survival curve for person 1}

quant.prob=seq(0.05,0.95,by=0.05)
survprob = predict(recid.aft.w, type = "quantile", se.fit = TRUE,p = quant.prob)
surv.prob=rev(quant.prob)
graph.dat=data.frame(cbind(survprob$fit[1,],surv.prob))
colnames(graph.dat)=c("Tenure","SurvivalProb")
ggplot(graph.dat,aes(x=Tenure,y=SurvivalProb))+geom_line(color="blue")+labs(title="Survival Curve for Person 1",x="Tenure",y="Survival Probability")


```

## Finding probabilities of a given value

We just predicted quantiles.  We can go the opposite direction and find probabilities.  To do this, the survreg function allows us to simply do psurvreg (we could have actually used qsurvreg for the previous piece in getting quantiles!!).  Keep in mind that psurvreg is for the FAILURE probability (to get survival probabilities, we need to take 1-p, where p is the failure probability).

The below code finds the survival probability for each observed time!  For example, person 1 was arrested on week 20 (where did that fall on their predicted survival curve?). Person 2 was arrested in week 17 (where did that fall on its predicted survival curve?).

```{r Percentiles from AFT}
survprob.actual = 1 - psurvreg(recid$week,
      mean = predict(recid.aft.w, type = "lp"),
      scale = recid.aft.w$scale, distribution =     recid.aft.w$dist)
head(survprob.actual, n = 10)


```

We can also do this for a given point in time (say 10 weeks)....

```{r Survival prob for 10 weeks AFT}
survprob.10wk = 1 - psurvreg(10,
    mean = predict(recid.aft.w, type = "lp"),
    scale = recid.aft.w$scale,
    distribution = recid.aft.w$dist)
head(survprob.10wk)

```


## Python Code

Python Code to create and fit models:

Weibull model:

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from lifelines import WeibullAFTFitter

recid = r.recid

recid1=recid[['fin','age','wexp','mar','paro','prio','week','arrest']]
aft = WeibullAFTFitter()
aft.fit(recid1, duration_col='week', event_col='arrest',ancillary=False )

aft.print_summary(3)

## Note that Rho is the shape parameter.


aft.plot()



```

Log Logistic model:

```{python}

from lifelines import LogLogisticAFTFitter

aft = LogLogisticAFTFitter()
aft.fit(recid1, duration_col='week', event_col='arrest' )

aft.print_summary(3)

aft.plot()

```

Log Normal model:

```{python}
from lifelines import LogNormalAFTFitter

aft = LogNormalAFTFitter()
aft.fit(recid1, duration_col='week', event_col='arrest' )

aft.print_summary(3)

aft.plot()

```



## Interesting application 
To see the impact of the financial variable, we can look at those who did NOT have financial aid and what would they look like if they did have financial aid (impact of providing financial aid).

```{r Impact of financial aid}
# Predicted Change in Event Time #
failprob.actual = psurvreg(recid$week,
      mean = predict(recid.aft.w, type = "lp"),
      scale = recid.aft.w$scale, distribution =     recid.aft.w$dist)
head(survprob.actual, n = 10)

new_time = qsurvreg(failprob.actual,
  mean = predict(recid.aft.w, type = "lp") +
  coef(recid.aft.w)['fin'],
  scale = recid.aft.w$scale,
  distribution = recid.aft.w$dist)

recid$new_time = new_time
recid$diff = recid$new_time - recid$week

impact.fin=data.frame(recid$week, recid$new_time, recid$diff,recid$arrest,recid$fin)
colnames(impact.fin)=c("O.Week","N.Week","Diff","Arrest","Fin")


impact.fin2=subset(impact.fin,Arrest==1 & Fin==0)
head(impact.fin2)

```

