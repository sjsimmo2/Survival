# Introduction to Survival

Welcome to the Survival Analysis module!  This document will be periodically udated throughout the course.  As always, first thing we need to do is get all of the packages needed for the course:

```{r packages,message=F}
library(survival)
library(foreign)
library(ggplot2)
library(survminer)
library(rms)
library(flexsurv)
library(dplyr)
library(ciTools)
library(here)
library(visreg)
library(cmprsk)

library(reticulate)

use_python("C:\\ProgramData\\Anaconda3\\python.exe")
```

The data sets we will be using are located on AWS in the survival2024 bucket.  Here is an example code of how to get the bladder data set from this bucket: 

```{r data sets}
library(aws.s3)

#Finding the AWS S3 bucket
bucket_exists(
  bucket = "s3://survival2024/",
  region = "us-east-1"
)


files <- get_bucket_df(
  bucket = "s3://survival2024/",
  region = "us-east-1",
  max = 20000
) %>%
  as_tibble()

#Downloading files
save_object(
  object = "bladder.csv",
  bucket = "s3://survival2024/",
  region = "us-east-1",
  file = "bladder"
)

#You can now start Wrangling the data...
df <- read.csv("bladder")


##### Datasets on AWS for survival:
# bladder.csv
# heart.csv
# hurricane.csv
# leaders.csv
# liver.csv
# loyalty.csv
# lung_R.csv
# recid.csv
# recid_lag.csv
# recid_long.csv

```


```{r, include=FALSE}
loyalty=read.csv("Q:/My Drive/Fall 3 - Survival Analysis/loyalty.csv",header=T)
recid=read.csv("Q:/My Drive/Fall 3 - Survival Analysis/recid.csv",header=T)
recid_long=read.csv("Q:/My Drive/Fall 3 - Survival Analysis/recid_long.csv",header=T)
recid_lag=read.csv("Q:/My Drive/Fall 3 - Survival Analysis/recid_lag.csv",header=T)
leaders = read.csv(file = "Q:/My Drive/Fall 3 - Survival Analysis/leaders.csv", header = TRUE)
bladder = read.csv(file = "Q:/My Drive/Fall 3 - Survival Analysis/bladder.csv", header = TRUE)

```

To perform a survival analysis, you need to identify which variable has the "time" information and which variable contains the "censoring" information.  This is done through the Surv function.  We should always visualize our data and one of the most useful visualizations is the Kaplan-Meier curve (also shown in the code below).

```{r survival curves}
simple=data.frame(matrix(c(7,8,10,3,2,3,1,1,0,1,1,0),ncol=2))
colnames(simple)=c("tenure","censored")

# Create a Survival Analysis Object 
simple.s=Surv(time=simple$tenure,event=simple$censored)


# Create a Kaplan-Meier Survival Curve with Censoring 
simple_km=survfit(Surv(time = tenure, event = censored)~1,                      data = simple)
summary(simple_km)
plot(simple_km, main = "Survival Function", xlab = "Tenure", ylab = "Survival Probability")

loyalty.fit=survfit(Surv(Tenure, censored)~1,data=loyalty)
summary(loyalty.fit)
plot(loyalty.fit)

recid.fit = survfit(Surv(week, arrest)~1,data=recid)
summary(recid.fit)
ggsurvplot(recid.fit, data = recid, conf.int = T, palette = "purple", xlab = "Week", ylab = "Survival Probability", legend = "none", break.y.by = 0.1)


```

### Python for Survival Curves 

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sksurv.nonparametric import kaplan_meier_estimator
from lifelines import KaplanMeierFitter
from lifelines import NelsonAalenFitter

simple=pd.DataFrame(data={'Censored': [1,1,0,1,1,0], 'Tenure': [7,8,10,3,2,3]})
km = KaplanMeierFitter()

km.fit(durations = simple['Tenure'],event_observed=simple['Censored'])
km.event_table
km.survival_function_
km.plot()
plt.title("Survival Plot using K-M")
plt.ylabel("Probability")
plt.show()



km.plot_cumulative_density()


```


## Stratified Analysis

We can look at Survival curves segmented into different groups or strata (if we want to see if the likelihood of survival changes based on what group you are in).  You need to define the variable that creates the strata in order to create this analysis.  As always, to truly see if there is a difference, you should perform a statistical analysis test (there are two different tests illustrated in the following code).

```{r stratified analysis}
Loyal.KP2 = survfit(Surv(Tenure, censored) ~ Loyalty,data=loyalty)
ggsurvplot(Loyal.KP2,data=loyalty,palette = c("blue","orange"),conf.int = T)

Recid.KP = survfit(Surv(week, arrest) ~ wexp,data=recid)
ggsurvplot(Recid.KP,data=recid,palette = c("blue","orange"),conf.int = T,legend.title = "work experience", legend.labs = c("no", "yes"))


```

Testing differences in survival curves:

```{r}
# Test for Differences in Survival Curves #

# Log-Rank Test
survdiff(Surv(Tenure, censored) ~ Loyalty, data=loyalty, rho=0) 

# Wilcoxon Test 
survdiff(Surv(Tenure, censored) ~ Loyalty, data=loyalty, rho=1) 
 
# Log-Rank Test 
survdiff(Surv(week, arrest) ~ wexp, data=recid,rho=0)

# Wilcoxon Test 
survdiff(Surv(week, arrest) ~ wexp,data=recid,rho=1) 

```


### Python for stratified analysis

```{python}


loyalty=r.loyalty

cen_loy=loyalty["censored"]
time_loy=loyalty["Tenure"]

ax = plt.subplot(111)

loy = (loyalty["Loyalty"] == 0)
kmf = KaplanMeierFitter()
kmf.fit(time_loy[loy], event_observed=cen_loy[loy], label="No program")
kmf.plot_survival_function(ax=ax)

kmf.fit(time_loy[~loy], event_observed=cen_loy[~loy], label="Program members")
kmf.plot_survival_function(ax=ax)

plt.title("Loyalty program")
plt.show()


```

Using the recidivism data set.

```{python}
from lifelines.statistics import logrank_test

recid = r.recid

cen_recid=recid["arrest"]
time_recid=recid["week"]

ax = plt.subplot(111)

no_work = (recid["wexp"] == 0)
kmf = KaplanMeierFitter()
kmf.fit(time_recid[no_work], event_observed=cen_recid[no_work], label="No prior work")
kmf.plot_survival_function(ax=ax)

kmf.fit(time_recid[~no_work], event_observed=cen_recid[~no_work], label="Work experience")
kmf.plot_survival_function(ax=ax)

plt.title("Work experience")
plt.show()

results = logrank_test(time_recid[no_work], time_recid[~no_work], cen_recid[no_work], cen_recid[~no_work], alpha=.99)

results.print_summary()



## There is also a multivariate_logrank_test for when you have more than two groups to compare and a pairwise_logrank_test to do multiple comparisons.


results = logrank_test(time_recid[no_work], time_recid[~no_work], cen_recid[no_work], cen_recid[~no_work], weightings="wilcoxon",alpha=.99)

results.print_summary()


```


## Hazard function

We are able to calculate hazard probabilities and cumulative hazard functions in R.

```{r hazard functions}

# Calculating Hazard Probabilities 
h= simple_km$n.event/simple_km$n.risk
index.h=rep(0,length=(max(simple$tenure)+1)) #Need to add 0
index.h[(simple_km$time)+1]=h #Because of 0
haz.plot=data.frame(cbind(seq(0,max(simple$tenure)), index.h))
colnames(haz.plot)=c("Time","Hazard")
ggplot(haz.plot,aes(x=Time,y=Hazard))+geom_line()

h = loyalty.fit$n.event/loyalty.fit$n.risk
index.h=rep(0,length=(max(loyalty$Tenure)+1)) #Need to add 0
index.h[(loyalty.fit$time)+1]=h #Because of 0
haz.plot=data.frame(cbind(seq(0,max(loyalty$Tenure)), index.h))
colnames(haz.plot)=c("Time","Hazard")
ggplot(haz.plot,aes(x=Time,y=Hazard))+geom_line()

h = recid.fit$n.event/recid.fit$n.risk
index.h=rep(0,length=(max(recid$week)+1)) #Need to add 0
index.h[(recid.fit$time)+1]=h #Because of 0
haz.plot=data.frame(cbind(seq(0,max(recid$week)), index.h))
colnames(haz.plot)=c("Time","Hazard")
ggplot(haz.plot,aes(x=Time,y=Hazard))+geom_line()

ggsurvplot(recid.fit, data = recid, fun = "cumhaz", conf.int = TRUE,  palette = "purple", xlab = "Week",           ylab = "Cumulative Hazard", legend = "none")


###Cumulative hazard function

h= simple_km$n.event/simple_km$n.risk
index.h=rep(0,length=(max(simple$tenure)+1)) #Need to add 0
index.h[(simple_km$time)+1]=h #Because of 0
cum.haz=cumsum(index.h)
haz.plot=data.frame(cbind(seq(0,max(simple$tenure)), cum.haz))
colnames(haz.plot)=c("Time","Hazard")
ggplot(haz.plot,aes(x=Time,y=Hazard))+geom_line()+labs(y="Cumulative Hazard")

ggsurvplot(
  Recid.KP,
  data = recid,
  size = 1,                 
  palette =
    c("blue","orange"),
  conf.int = TRUE,          
  pval = TRUE,              
  risk.table = TRUE,        
  risk.table.col = "wexp",
  legend.labs =
    c("No", "Yes"),    
  risk.table.height = 0.25, 
  ggtheme = theme_bw()      
)


```

### Python for Hazard function



```{python}

km_val = km.event_table

hazard = km_val.observed/km_val.at_risk

hazard
cum_haz=NelsonAalenFitter()
cum_haz.fit(durations = simple['Tenure'],event_observed=simple['Censored'])
cum_haz.plot_cumulative_hazard()
```
