# Survival Analysis

Welcome to the Survival Analysis module!  This document will be periodically udated throughout the course.  As always, first things we need to do is get all of the packages needed for the course:

```{r packages,message=F}
library(survival)
library(foreign)
library(ggplot2)
library(survminer)
library(rms)
library(flexsurv)
library(dplyr)
library(ciTools)
library(here)
library(visreg)
library(cmprsk)
```

Also need to get data sets that will be used throughout this course: 

```{r data sets}
loyalty=read.csv("Q:\\My Drive\\Fall 3 2016 Survival Analysis\\Data\\Data_R\\loyalty.csv",header=T)
recid=read.csv("Q:\\My Drive\\Fall 3 2016 Survival Analysis\\Data\\Data_R\\recid.csv",header=T)
recid_long=read.csv("Q:\\My Drive\\Fall 3 2016 Survival Analysis\\Data\\Data_R\\recid_long.csv",header=T)
recid_lag=read.csv("Q:\\My Drive\\Fall 3 2016 Survival Analysis\\Data\\Data_R\\recid_lag.csv",header=T)
leaders = read.csv(file = "Q:\\My Drive\\Fall 3 2016 Survival Analysis\\Data\\Data_R\\leaders.csv", header = TRUE)
bladder = read.csv(file = "Q:\\My Drive\\Fall 3 2016 Survival Analysis\\Data\\Data_R\\bladder.csv", header = TRUE)
simple=data.frame(matrix(c(7,8,10,3,2,3,1,1,0,1,1,0),ncol=2))
colnames(simple)=c("tenure","censored")

```

To perform a survival analysis, you need to identify which variable has the "time" information and which variable contains the "censoring" information.  This is done through the Surv function.

```{r survival curves}
# Create a Survival Analysis Object 
simple.s=Surv(time=simple$tenure,event=simple$censored)


# Create a Kaplan-Meier Survival Curve with Censoring 
simple_km=survfit(Surv(time = tenure, event = censored)~1,                      data = simple)
summary(simple_km)
plot(simple_km, main = "Survival Function", xlab = "Tenure", ylab = "Survival Probability")

loyalty.fit=survfit(Surv(Tenure, censored)~1,data=loyalty)
summary(loyalty.fit)
plot(loyalty.fit)

recid.fit = survfit(Surv(week, arrest)~1,data=recid)
summary(recid.fit)
ggsurvplot(recid.fit, data = recid, conf.int = T, palette = "purple", xlab = "Week", ylab = "Survival Probability", legend = "none", break.y.by = 0.1)


```

## Stratified Analysis

We can look at Survival curves segmented into different groups or strata.  You need to define the variable that creates the strata in order to create this analysis.

```{r stratified analysis}
Loyal.KP2 = survfit(Surv(Tenure, censored) ~ Loyalty,data=loyalty)
ggsurvplot(Loyal.KP2,data=loyalty,palette = c("blue","orange"),conf.int = T)

Recid.KP = survfit(Surv(week, arrest) ~ wexp,data=recid)
ggsurvplot(Recid.KP,data=recid,palette = c("blue","orange"),conf.int = T,legend.title = "work experience", legend.labs = c("no", "yes"))

# Test for Differences in Survival Curves #
survdiff(Surv(Tenure, censored) ~ Loyalty, data=loyalty, rho=0) 
# Log-Rank Test 
survdiff(Surv(Tenure, censored) ~ Loyalty, data=loyalty, rho=1) 
# Wilcoxon Test 

survdiff(Surv(week, arrest) ~ wexp, data=recid,rho=0) # Log-Rank Test 
survdiff(Surv(week, arrest) ~ wexp,data=recid,rho=1) # Wilcoxon Test 

```

## Hazard function

We are able to calculate hazard probabilities and cumulative hazard functions in R.

```{r hazard functions}

# Calculating Hazard Probabilities 
h= simple_km$n.event/simple_km$n.risk
index.h=rep(0,length=(max(simple$tenure)+1)) #Need to add 0
index.h[(simple_km$time)+1]=h #Because of 0
haz.plot=data.frame(cbind(seq(0,max(simple$tenure)), index.h))
colnames(haz.plot)=c("Time","Hazard")
ggplot(haz.plot,aes(x=Time,y=Hazard))+geom_line()

h = loyalty.fit$n.event/loyalty.fit$n.risk
index.h=rep(0,length=(max(loyalty$Tenure)+1)) #Need to add 0
index.h[(loyalty.fit$time)+1]=h #Because of 0
haz.plot=data.frame(cbind(seq(0,max(loyalty$Tenure)), index.h))
colnames(haz.plot)=c("Time","Hazard")
ggplot(haz.plot,aes(x=Time,y=Hazard))+geom_line()

h = recid.fit$n.event/recid.fit$n.risk
index.h=rep(0,length=(max(recid$week)+1)) #Need to add 0
index.h[(recid.fit$time)+1]=h #Because of 0
haz.plot=data.frame(cbind(seq(0,max(recid$week)), index.h))
colnames(haz.plot)=c("Time","Hazard")
ggplot(haz.plot,aes(x=Time,y=Hazard))+geom_line()

ggsurvplot(recid.fit, data = recid, fun = "cumhaz", conf.int = TRUE,  palette = "purple", xlab = "Week",           ylab = "Cumulative Hazard", legend = "none")


###Cumulative hazard function

h= simple_km$n.event/simple_km$n.risk
index.h=rep(0,length=(max(simple$tenure)+1)) #Need to add 0
index.h[(simple_km$time)+1]=h #Because of 0
cum.haz=cumsum(index.h)
haz.plot=data.frame(cbind(seq(0,max(simple$tenure)), cum.haz))
colnames(haz.plot)=c("Time","Hazard")
ggplot(haz.plot,aes(x=Time,y=Hazard))+geom_line()+labs(y="Cumulative Hazard")

ggsurvplot(
  Recid.KP,
  data = recid,
  size = 1,                 
  palette =
    c("blue","orange"),
  conf.int = TRUE,          
  pval = TRUE,              
  risk.table = TRUE,        
  risk.table.col = "wexp",
  legend.labs =
    c("No", "Yes"),    
  risk.table.height = 0.25, 
  ggtheme = theme_bw()      
)


```

## AFT

The following R codes illustrate how to fit the Accelerated Failure Time models.

```{r AFT}

# Accelerated Failure Time Model 
recid.aft.ln <- survreg(Surv(week, arrest) ~ fin + age + mar + prio, data = recid, dist = 'lognormal')
summary(recid.aft.ln)
#Parameter interpretation
(exp(coef(recid.aft.ln))-1)*100

# Exponential vs. Weibull 
recid.aft.w <- survreg(Surv(week, arrest) ~ fin + age  + wexp + mar + paro + prio, data = recid, dist = 'weibull')
summary(recid.aft.w)

# Checking Distributions 
recid.aft.w <- flexsurvreg(Surv(week, arrest) ~ fin + age + wexp + mar + paro + prio, data = recid, dist = "weibull")

plot(recid.aft.w, type = "cumhaz", ci = TRUE, conf.int = FALSE, las = 1, bty = "n",
     xlab = "week", ylab = "Cumulative Hazard", main = "Weibull Distribution")

recid.aft.e <- flexsurvreg(Surv(week, arrest) ~ fin + age + wexp + mar + paro + prio, data = recid, dist = "exp")

plot(recid.aft.e, type = "cumhaz", ci = TRUE, conf.int = FALSE, las = 1, bty = "n",
     xlab = "week", ylab = "Cumulative Hazard", main = "Exponential Distribution")

recid.aft.g <- flexsurvreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = "gamma")

plot(recid.aft.g, type = "cumhaz", ci = TRUE, conf.int = FALSE, las = 1, bty = "n",
     xlab = "week", ylab = "Cumulative Hazard", main = "Gamma Distribution")

recid.aft.ll <- flexsurvreg(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data = recid, dist = "llogis")

plot(recid.aft.ll, type = "cumhaz", ci = TRUE, conf.int = FALSE, las = 1, bty = "n",
     xlab = "week", ylab = "Cumulative Hazard", main = "Log-Logistic Distribution")

# Goodness-of-Fit Tests 

like.e = flexsurvreg(Surv(week, arrest) ~ fin + age +  wexp + mar + paro + prio, data = recid, dist = "exp")$loglik
like.w <- flexsurvreg(Surv(week, arrest) ~ fin + age +  wexp + mar + paro + prio, data = recid, dist = "weibull")$loglik
like.ln <- flexsurvreg(Surv(week, arrest) ~ fin + age +  wexp + mar + paro + prio, data = recid, dist = "lnorm")$loglik
like.g = flexsurvreg(Surv(week, arrest) ~ fin + age  + wexp + mar + paro + prio, data = recid, dist = "gamma")$loglik
like.ll = flexsurvreg(Surv(week, arrest) ~ fin + age  + wexp + mar + paro + prio, data = recid, dist = "llogis")$loglik
like.f = flexsurvreg(Surv(week, arrest) ~ fin + age  + wexp + mar + paro + prio, data = recid, dist = "genf")$loglik

pval.e.g = pchisq((-2*(like.e-like.g)), 2,lower.tail=F)
pval.w.g = pchisq((-2*(like.w-like.g)), 1,lower.tail=F)
pval.ln.g = pchisq((-2*(like.ln-like.g)), 1,lower.tail=F)
##pval.g.f = pchisq((-2*(like.g-like.f)), 1,lower.tail=F)


Tests = c('Exp vs. Gam', 'Wei vs. Gam', 'LogN vs. Gam')
P_values = c(pval.e.g, pval.w.g, pval.ln.g)
cbind(Tests, P_values)

# Predicted Survival Quantiles 
recid.aft.w = survreg(Surv(week, arrest) ~ fin + age +prio, data = recid, dist = 'weibull')
summary(recid.aft.w)

survprob.75.50.25 = predict(recid.aft.w, type = "quantile", se.fit = TRUE,p = c(0.25, 0.5, 0.75))
head(survprob.75.50.25$fit)

# Predicted Mean Event Time #
p.time.mean = predict(recid.aft.w, type = "response", se.fit = TRUE)
head(p.time.mean$fit, n = 10)

# Predicted Survival Probabilities #
survprob.actual = 1 - psurvreg(recid$week,
      mean = predict(recid.aft.w, type = "lp"),
      scale = recid.aft.w$scale, distribution =     recid.aft.w$dist)
head(survprob.actual, n = 10)

survprob.10wk = 1 - psurvreg(10,
    mean = predict(recid.aft.w, type = "lp"),
    scale = recid.aft.w$scale,
    distribution = recid.aft.w$dist)
head(survprob.10wk)

# Predicted Change in Event Time #
new_time = qsurvreg(1 - survprob.actual,
  mean = predict(recid.aft.w, type = "lp") +
  coef(recid.aft.w)['fin'],
  scale = recid.aft.w$scale,
  distribution = recid.aft.w$dist)

recid$new_time = new_time
recid$diff = recid$new_time - recid$week

head(data.frame(recid$week, recid$new_time, recid$diff), n = 10)


```

### Breaking down the above code into smaller pieces!

In the survival regression, when we use the predict command (with nothing else), this is predicting the mean survival time.  This means, on average when do we think the event will occur?  For example, we will continue to use the recidivism data set with the Weibull distribution with the variables fin, age and prior.  The following command will predict the mean time of the event occurring (only printing off a few to see).
```{r AFT predict mean}

recid.aft.w = survreg(Surv(week, arrest) ~ fin + age +prio, data = recid, dist = 'weibull')
head(predict(recid.aft.w))

```

But does it make sense to predict on average when we think an event will occur (or when an event will fail)? Probably not.  Another approach would be to print the quantiles (for example the 25th, 50th and 75th quantile).

```{r AFT quantiles}

survprob.75.50.25 = predict(recid.aft.w, type = "quantile", se.fit = TRUE,p = c(0.25, 0.5, 0.75))
head(survprob.75.50.25$fit)
```

Did you know that from this regression, each observation has their own survival curve?  That is why we can get quantiles (we can go the "opposite" direction and get percentiles too!).  Below you will find the survival curve for person 1...

```{r Survival curve for person 1}

quant.prob=seq(0.05,0.95,by=0.05)
survprob = predict(recid.aft.w, type = "quantile", se.fit = TRUE,p = quant.prob)
surv.prob=rev(quant.prob)
graph.dat=data.frame(cbind(survprob$fit[1,],surv.prob))
colnames(graph.dat)=c("Tenure","SurvivalProb")
ggplot(graph.dat,aes(x=Tenure,y=SurvivalProb))+geom_line(color="blue")+labs(title="Survival Curve for Person 1",x="Tenure",y="Survival Probability")


```
We just predicted quantiles.  We can go the opposite direction and find probabilities.  To do this, the survreg function allows us to simply do psurvreg (we could have actually used qsurvreg for the previous piece in getting quantiles!!).  Keep in mind that psurvreg is for the FAILURE probability (to get survival probabilities, we need to take 1-p, where p is the failure probability).

The below code finds the survival probability for each observed time!  For example, person 1 was arrested on week 20 (where did that fall on their predicted survival curve?). Person 2 was arrested in week 17 (where did that fall on its predicted survival curve?).

```{r Percentiles from AFT}
survprob.actual = 1 - psurvreg(recid$week,
      mean = predict(recid.aft.w, type = "lp"),
      scale = recid.aft.w$scale, distribution =     recid.aft.w$dist)
head(survprob.actual, n = 10)


```

We can also do this for a given point in time (say 10 weeks)....

```{r Survival prob for 10 weeks AFT}
survprob.10wk = 1 - psurvreg(10,
    mean = predict(recid.aft.w, type = "lp"),
    scale = recid.aft.w$scale,
    distribution = recid.aft.w$dist)
head(survprob.10wk)

```

To see the impact of the financial variable, we can look at those who did NOT have financial aid and what would they look like if they did have financial aid (impact of providing financial aid).

```{r Impact of financial aid}
# Predicted Change in Event Time #
new_time = qsurvreg(1 - survprob.actual,
  mean = predict(recid.aft.w, type = "lp") +
  coef(recid.aft.w)['fin'],
  scale = recid.aft.w$scale,
  distribution = recid.aft.w$dist)

recid$new_time = new_time
recid$diff = recid$new_time - recid$week

impact.fin=data.frame(recid$week, recid$new_time, recid$diff,recid$arrest,recid$fin)
colnames(impact.fin)=c("O.Week","N.Week","Diff","Arrest","Fin")


impact.fin2=subset(impact.fin,Arrest==1 & Fin==0)
head(impact.fin2)

```

# Cox Regression

The following code fits the Proportional Cox Hazard model.

```{r Cox Regression}

# Proportional Hazards Model #
recid.ph <- coxph(Surv(week, arrest) ~ fin + age + wexp + mar +paro + prio, data = recid)
summary(recid.ph)

# Parameter Interpretation #
recid.ph2 <- coxph(Surv(week, arrest) ~ fin + age + prio, data = recid)
summary(recid.ph2)

(exp(coef(recid.ph2))-1)*100

# Automatic Selection Techniques #
full.model <- coxph(Surv(week, arrest) ~ fin + age + wexp + mar +paro + prio, 
                    data = recid)

empty.model <- coxph(Surv(week, arrest ) ~ 1, data = recid)

step.model <- step(empty.model, 
                      scope = list(lower=formula(empty.model), 
                                   upper=formula(full.model)), 
                      direction = "both")
summary(step.model)

full.model <- coxph(Surv(week, arrest) ~ fin + age  + wexp + mar +paro + prio, 
                    data = recid)

back.model <- step(full.model, direction = "backward")
summary(back.model)

full.model <- coxph(Surv(week, arrest) ~ fin + age  + wexp + mar +paro + prio, 
                    data = recid)

empty.model <- coxph(Surv(week, arrest) ~ 1, data = recid)

for.model <- step(empty.model, 
                  scope = list(lower=formula(empty.model), 
                               upper=formula(full.model)), 
                  direction = "forward")
summary(for.model)

# Estimated Survival Curves #
newdata <- data.frame(fin = c(1, 0), age = 30, wexp = c(1, 0),
                      mar = 0, paro = 0, prio = c(0, 4))

ggsurvplot(survfit(recid.ph, newdata), data = newdata, break.y.by = 0.1,
           palette = c("purple", "black"), ylab = "survival probability",
           xlab = "week", legend.labs = c("1", "2"), legend.title = "subject")


```


## Diagnostics

Assumptions made for the Cox PH model is linearity for the continuous variables and proportional hazards throughout time (i.e. at EACH time point, the proportion between the hazards remains the same!).  We can assess both of these through use of residuals.

```{r PH diagnostics}

# Concordance 
recid.ph = coxph(Surv(week, arrest) ~ fin + age + prio, data = recid)
concordance(recid.ph)

## Partial residuals...Linearity
recid.ph <- coxph(Surv(week, arrest) ~ fin + age + wexp + mar +paro + prio, data = recid)

visreg(recid.ph, "age", xlab = "age", ylab = "partial residuals",        gg = TRUE, band = FALSE) +  geom_smooth(col = "red", 
    fill = "red") + theme_bw() 


visreg(recid.ph, "prio", xlab = "#prior convictions", ylab = "partial residuals",    gg = TRUE, band = FALSE) +  geom_smooth(col = "red", fill = "red") + theme_bw()

## Martingale residuals...Linearity
recid.lin <- coxph(Surv(week, arrest) ~  age + prio, data = recid)
survminer::ggcoxfunctional(recid.lin,data=recid)

## Try transformations
recid.lin <- coxph(Surv(week, arrest) ~  sqrt(age) , data = recid)
survminer::ggcoxfunctional(recid.lin,data=recid)


# Proportional Hazard Test - Schoenfeld Residuals 
recid.ph.zph <- cox.zph(recid.ph, transform = "identity")
recid.ph.zph

ggcoxzph(recid.ph.zph)

# Can try transformations..
recid.ph.zph2 = cox.zph(recid.ph, transform = "km")
recid.ph.zph2

recid.ph.zph3 = cox.zph(recid.ph, transform = "identity")
recid.ph.zph3

recid.ph.zph4 = cox.zph(recid.ph, transform = "log")
recid.ph.zph4

```

If we believe that the PH assumption is not true for one (or more) variables, then we can explore what type of relationship is the best (with respect to time).  Options are "identity", "log" and "KM" (although identity and log are the most commonly used).  The first part of the code below illustrates how to fit the time-dependent coefficients.

The second part of the R code below illustrates how to fit  time-varying variables (variables that change their values throughout time).


```{r Time-varying information}

# Time-Dependent Coefficients #
recid.ph.tdc <- coxph(Surv(week, arrest) ~ fin +  wexp + mar + paro + prio+ age + tt(age), data = recid,
                 tt = function(x, time, ...){x*log(time)})
summary(recid.ph.tdc)

recid.ph.tdc <- coxph(Surv(week, arrest) ~  fin + prio +  age + tt(age), data = recid,
        tt = function(x, time, ...){x*log(time)})
summary(recid.ph.tdc)

# Time Varying Variables #
recid_long.ph <- coxph(Surv(start, stop, arrested) ~ fin + age + prio + employed, data = recid_long)
summary(recid_long.ph)

recid_lag.ph <- coxph(Surv(start, stop, arrested) ~ fin + age +  prio + employed, data = recid_lag)
summary(recid_lag.ph)


```
# Competing Risks

The following code illustrates how to do a competing risk model.

```{r Competing Risks}
leaders$lost = factor(leaders$lost, 0:3, labels = c("In-Office", "Constitutional", "Natural", "Non-Constitutional"))

# Cumulative Incidence Functions #
  cif.dat=leaders[leaders$lost!="In-Office",]  
  cif.tenure=cif.dat$years
  cif.status=cif.dat$lost

  cif.leaders=cuminc(cif.tenure,cif.status,rho=0)
  ggcompetingrisks(cif.leaders)
# Cox Regression Competing Risks #
 tenure=leaders$years
 View(leaders)
 status.leaders=leaders$lost
 x=leaders[,3:12]
 x$africa=ifelse(leaders$region==1,1,0)
 x$asia=ifelse(leaders$region==2,1,0)
 x$latin=ifelse(leaders$region==3,1,0)
 
 gray.natural=crr(tenure,status.leaders,x,failcode="Natural")
 summary(gray.natural)

 gray.const=crr(tenure,status.leaders,x,failcode="Constitutional")
 summary(gray.const)

 gray.nonconst=crr(tenure,status.leaders,x,failcode="Non-Constitutional")
 summary(gray.nonconst)

```

# Repeated Events

```{r Repeated Events}

# Independence Model (Andersen-Gill approach)
bladder.td <- coxph(Surv(start, stop, event == 1) ~ rx + number + size , data = bladder)
summary(bladder.td)

# Independence Model - Marginal means 
bladder.rse <- coxph(Surv(start, stop, event == 1) ~ rx + number + size + cluster(id), data = bladder)
summary(bladder.rse)

# Conditional Model - Assuming Variable Effects Same Across Strata - PWP model
bladder.con <- coxph(Surv(start, stop, event == 1) ~ rx + number + size + strata(enum)+cluster(id), data = bladder)
summary(bladder.con)

# Conditional Model - Assuming Variable Effects change Across Strata - PWP model
bladder.con <- coxph(Surv(start, stop, event == 1) ~ strata(enum)*rx + strata(enum)*number + strata(enum)*size + cluster(id), data = bladder)
summary(bladder.con)


# Gap Time Model - Assuming Variable Effects Same Across Strata #
# Can easily extend the gap time model to assume variable effects different same as above. #
bladder.gap <- coxph(Surv(time = (stop - start), event == 1) ~ rx + number + size + strata(enum) +cluster(id), data = bladder)
summary(bladder.gap)

```

